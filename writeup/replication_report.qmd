---
title: "Replication of a visual search experiment by Najemnik & Geisler (2005, Nature)"
author: "Hyunwoo Gu (hwgu@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
# bibliography: reference.bibtex
format: html
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction
Visual search is an active visual scan of environmental scenes, commonly taking place in everyday situations for people with vision. The visual search experiment by Najemnik & Geisler (2005) is of particular interest, since it presents a rigorous methodology that can be applied for studying the process of naturalistic visual scene understanding. Because the authors only presented the data from themselves as experiment subjects, it is worth considering a replication study with a participant pool naive to the purpose of the experiment.

The experimental stimulus was a windowed sine-wave grating randomly positioned (or not) in the background of spatial $1/f$ noise. The task was to find the target as quickly as possible and press a button when the target is located, starting from the central fixation point for each trial. An expected challenge will be to implement the ideal searcher model, as the main analysis is to compare human behavior to random versus ideal searcher models.

#### Links
-   [Project repository](https://github.com/psych251/najemnik2005)
-   [Original paper](https://github.com/psych251/najemnik2005/blob/master/original_paper/najemnik2005.pdf)
-   [Experimental paradigm](https://hyunwoogu.github.io/exp/visual_search) (For online demo. Main experiment done in-lab.)
-   [Preregistration](https://osf.io/ezhvy/)


## Methods

### Power Analysis
No formal statistical testing was reported in the original paper. 

Nonetheless, it is possible to construct a statistical test relevant to the main finding ([Figure 4a](#original_figure)). Here, I will use the [nested linear model comparison](#key_analysis) to test whether the observed human data differs from the random searcher prediction, under two levels of background noise contrast. The corresponding effect size will be $\eta^2$. To perform power analysis, the original effect size will be estimated from the original figure.

### Planned Sample
Planned sample size is $N=2$, with $192$ trials across $6$ blocks, following the original paper. Since the experiment requires precise eye tracking, participants will be recruited to join an in-lab experiment setting. Only participants with normal or corrected-to-normal vision will join this study. 

To ensure the psychophysics data quality, any participants with less than $70\%$ detection accuracy will be excluded from the analysis. To ensure eye-tracking data quality, a calibration trial will be performed before each block. Data from any failure to obtain reliable a scan path will be excluded before analysis. Fixations and saccades will be detected with EyeLink’s built-in algorithm.

### Materials
Quoted from the original paper:

> Stimuli were presented on a calibrated monochrome Image Systems monitor (M21L) with a white phosphor (P-104) and resolution $1024 \times 768$ pixels at $60$Hz. Eye position was measured with a Forward Technologies SRI Version 6 dual Purkinje eye tracker. Head position was maintained with a bite bar and headrest.

For the replication study, the stimuli will be presented on a CRT monitor (Trinitron 21-inch flat screen; Dell Computer Company) with the resolution of $1280 \times 960$ pixels at $100$Hz. Eye position will be measured with EyeLink 1000 Plus. Head position will be maintained with Tobii chin rest.

### Procedure
Quoted from the original paper:

> On each trial, the observer first fixated a dot at the centre of the display and then initiated the trial with a button press. The fixation dot disappeared immediately and a random time later (100–500 ms) the search display appeared. The observer’s task was to find the target as rapidly as possible and to press a button as soon as the target was located. The observer then indicated the judged target location by fixating that location and pressing the button again. The response was considered correct if the eye position at the time of the second button press was closer to the target location than to any other potential target location. Each session consisted of 6 blocks of 32 search trials. In each session the background noise contrast was fixed. Before each block, the eye tracker was calibrated and the search target for that block was shown on a uniform background at the centre of the display. The set of 12 conditions was repeated 6 times in a counterbalanced fashion.

### Analysis Plan<a name="key_analysis"></a>

**Key analysis of interest**. I will test whether human participants' number of fixations differs from the prediction of the random searcher model, given different levels of search target visibility and background noise contrast. To test this, the nested linear model comparison will be used as follows.

<a name="model"></a>

+ Null linear model: $(\mathrm{\#Fixations}) \sim (\mathrm{Target\ \ visibility}) \ast (\mathrm{Noise\ \ contrast})$
+ Full linear model: $(\mathrm{\#Fixations}) \sim (\mathrm{Target\ \ visibility}) \ast (\mathrm{Noise\ \ contrast}) \ast (\mathrm{Searcher})$

where $\ast$ denotes interaction, and the indicator variable `Searcher` specifies whether the data is from human or random searchers. The likelihood ratio test between the null and full models will be used for analysis, and $\eta^2$ will be computed to provide a comparable effect size.

**Secondary analysis**. Along with the main analysis, I will also compare whether participants behavior differs from the prediction of the ideal searcher model. Commonly, the model comparison is based on the model likelihoods, i.e. $p\left( 
\mathrm{\#Fixations} \vert \mathrm{Searcher\ \ Model} \right)$; however, the exact computation of the likelihood for the ideal searcher model is very convoluted and omitted from the original study, thus beyond the scope of this replication study. Alternatively, I will follow the same strategy of nested linear model comparison as above, but with the `Searcher` variable specifying whether data is from human or ideal searchers. 

**Model simulations**. Following the original study, the behaviors of random and ideal searchers will be simulated. These searchers' target probability map is defined as follows.

$$
\begin{align}
p_i(T) &= \frac{ \displaystyle \mathrm{prior}(i) \exp \left( \sum_{t=1}^T d'^2_{ik(t)} W_{ik(t)} \right) }{ \displaystyle \sum_{j=1}^n \mathrm{prior}(j) \exp \left( \sum_{t=1}^T d'^2_{jk(t)} W_{jk(t)} \right) } \tag{1}
\end{align}
$$
where $p_i(T)$: the posterior probability that the target is at location $i$ given $T$ fixations, $\mathrm{prior}(i)$: the prior probability that the target is at location $i$, $k(t)$: the location of $t$-th fixation, $d'_{ik(t)}$: the visibility from $k(t)$ to location $i$, and $W_{ik(t)}$: template response representing evidence obtained at location $i$ about the target from fixation at $k(t)$. The ideal searcher selects the next target $k^\ast(T+1)$ using the following formula given $p_i(T)$.

$$
\begin{align}
k^\ast(T+1) &= \operatorname{argmax}_{k(T+1)} \left( \sum_{i=1}^n p_i(T) p(C \vert i, k(T+1)) \right)  \tag{2}
\end{align}
$$
where $p(C \vert i, k(T+1))$: the probability of correct identification of the target at location $i$ from fixation at $k(T+1)$. The random searcher selects the next target randomly from possible locations. The procedure for simulation is quoted from the original paper:

> The six steps for each simulated search trial were as follows. First, fixation began at the centre of the display (as in the search experiment). Second, a target location was selected at random ($\mathrm{prior}(i)= 1/85$); $0.5$ was added to that location and $-0.5$ to all other locations. Third, a gaussian noise sample was generated for each of the $85$ potential target locations. The standard deviation of each noise sample was set to be consistent with the value of the visibility map at that location: $\sigma=1/d'$. Fourth, the posterior probability for each potential target location was calculated from equation (1). Fifth, if the maximum posterior probability exceeded a criterion, the search stopped. The criterion for each condition was picked so that the error rate of the ideal searcher approximated that of the humans. Sixth, for the ideal searcher, equation (2) was evaluated to select the next fixation location; for the random searcher, the next fixation location was selected at random. The process then jumped back to the third step. Note that the specific characteristics of the target and $1/f$ noise enter the simulation through the visibility maps.


### Differences from Original Study

+ Sample: While the original study used data from non-naive participants (i.e. authors), this project will recruit naive participants. Given the relatively low-level nature of eye movement, it is expected that this discrepancy will not make crucial difference.

+ Setting: This project used an advanced technology with respect to the resolution and the frame rates of monitor, and the eye-tracking device. However, considering that fixations are fairly easy to detect and relatively robust to location changes in the scale of stimuli in the original research, these settings will not make critical differences.

+ Procedure: Some hyperparameters for the model simulation will be different from the original study, since they were unspecified in the original study. This will make critical differences, since different hyperparameters will lead to different model simulations. I plan to contact the authors on model parameters to ensure using the same models.

+ Analysis plan: The main analysis will newly be constructed in this project, since the original study did not report any formal statistical testing. This can make crucial differences, since the original authors did not resort to this specific analysis for their conclusion. However, the main figure ([Figure 4a](#original_figure)) will be the target of replication, in which the difference between the random searcher model and the human behavior should be visually apparent.


### Methods Addendum (Post Data Collection)

#### Actual Sample
The actual sample size was $N=2$ as specified in the analysis plan. Participants were given unidentifiable IDs, namely, A and B. Since no participant met the pre-specified exclusion criteria of psychophysical performance, all the data from both participants were included. 

#### Differences from pre-data collection methods plan
**Monitor specification**. Instead of the Dell Trinitron CRT monitor, the VPixx monitor with the resolution of $1920\times1080$ pixels at $120$Hz was used.

**Calibration**. Due to the compatibility issues between Metal-based psychophysics software (MGL) and eye-tracker, performing eye-tracking calibration was particularly challenging. Thus, the calibration was performed only once before the visual search experiment, and I instructed participants to try not to make head movements during the experiment. 

**Measuring $d'$**. Mapping the $d'$ values to the participant-specific sets of target contrast levels required performing separate pre-experimental 'detection tasks', as quoted from the original paper:

> On each trial, the observer fixated a dot at the centre of the display (there was no fixation dot for foveal measurements). The fixation dot disappeared at the onset of the test stimuli, which consisted of two 250-ms intervals separated by 500 ms. One interval contained background noise alone, the other a different random sample of background noise with the target added. The observer judged which interval contained the target. If the observer’s fixation was not within 0.758 of the fixation dot when the test stimuli appeared, the trial was discarded. Within a session the target always appeared in the same location, which was indicated after each trial. Sixteen blocks ($4$ target contrasts $\times$ $4$ noise levels) of 32 trials were run in each session.

Deviating from the original paper (which requires $25\times512 = 12,800$ trials), the detection tasks were performed only for (two locations $\times$ two noise levels) of $280$ trials with staircase-based contrast levels, resulting in $4\times280=1,120$ trials in total. Estimating the subject-specific visibility map from the detection data was based on the psychometric function as quoted below:

> The data for each noise level, in each session, were fitted with a Weibull function:
$$
f(c) = 0.5 + 0.5\left[1-\mathrm{exp}(-(c/c_T)^s)\right]
$$
Both the $82\%$ correct threshold parameter $c_T$ and the steepness parameter $s$ were estimated by using maximum-likelihood methods.

Code for mapping each of the  $d'$ values ($3,3.5,4,5,6,7$) to target contrast levels can be found in the following [Jupyter notebook](https://github.com/psych251/najemnik2005). These levels were used for target contrasts in the main experiment.

## Results

### Data preparation

Initial data preparation included two parts:

-   **Human data pre-processing** ([Jupyter notebook](https://github.com/psych251/najemnik2005)): basic sanity checks for human searcher eye-tracking data, and the transformation into a 'tidy' format.
-   **Model data generation** ([Jupyter notebook](https://github.com/psych251/najemnik2005/blob/master/model/model.ipynb)): implementation of the model based on the original authors' parameter values, and the transformation of the simulated model searcher (ideal, random) behaviors into a 'tidy' format.
	
	
```{r}
# Data Preparation
## Load Relevant Libraries and Functions
library(tidyverse)

## Import data
data_searcher = read.csv('data/main/searcher_behavior.csv') # model searchers from the original paper
data_human    = read.csv('data/main/human_behavior.csv')    # human searcher (n=2)
data_eye      = read.csv('data/main/eye_track.csv')         # human eye fixation time-series data

## Data exclusion / filtering
### compute n_fixations from eye-tracking data
t_fix   = 1e-2  # small time value to suppress counting the initial fixation
n_trial = nrow(data_human)
n_fix   = vector(length=n_trial)
for (i_trial in 1:nrow(data_human)){
  # number of fixations = fixation onsets between stimulus onset & target detection
  n_fix[i_trial] = sum(
      (data_eye$t_start >= data_human$t_onset[i_trial] + t_fix) &
      (data_eye$t_start <= data_human$t_detect[i_trial])
  )
}

### exclude the ideal searcher model for the main linear model comparison
### summarize the searcher prediction
data_searcher$noise = as.factor(data_searcher$noise)
data_compare = data_searcher %>% select(visibility, noise, searcher, n_fixation) %>% filter(searcher=='random')

## Prepare data for analysis - create columns etc.
data_human_compare = data.frame( 
  visibility = data_human$visibility,
  noise      = as.factor(data_human$noise),
  searcher   = data_human$participant,
  n_fixation = n_fix
)
data_compare = rbind(data_compare, data_human_compare)
data_compare = data_compare %>% mutate(searcher = ifelse(searcher=='random', 'random', 'human')) # collapse human observers for linear model comparison
data_compare = data_compare %>% filter(visibility>=3, visibility<=7) # original study visibility range
```

### Confirmatory analysis

**Searcher model simulation**. Searcher model predictions were fully implemented using the original authors' parameter values. These predictions were overlaid on the human searcher data in the [replicated figure](#replication_figure), and included in the data to be used for the main statistical analysis.

**Nested linear model comparison**. As previously specified, the nested linear model comparison was performed to test whether the number of fixations differs from the prediction of the random searcher model, given different levels of search target visibility and background noise.

```{r}
null = lm(n_fixation ~ visibility*noise, data=data_compare)
full = lm(n_fixation ~ visibility*noise*searcher, data=data_compare)

# summary of each model
summary(null)
summary(full)

anova(null, full)
print(paste("Δeta-squared:", summary(full)$r.squared - summary(null)$r.squared))
```

Here, the full model led to a significantly improved fit over the null model, implying that the data differs from the random searcher behavior. Specifically, the null model's $\eta^2$ was `r round(summary(null)$r.squared,3)` and the full model's $\eta^2$ was `r round(summary(full)$r.squared,3)`, the difference being $\Delta \eta^2=$ `r round(summary(full)$r.squared-summary(null)$r.squared,3)`.

**Figure**. To visually inspect the comparison between the original paper and the replication, the behavioral number of fixations was plotted for each participant and background noise, as a function of target contrast levels (converted into $d'$). 

<a name="replication_figure"></a>

```{r}
data_human_compare %>% 
  ggplot(aes(x=visibility, y=n_fixation)) +
  stat_summary(fun.data=mean_se, aes(color=noise, shape=searcher)) + 
  stat_summary(data=data_searcher, fun.data=mean_se, geom='ribbon', alpha=0.15, aes(fill=noise, linetype=searcher)) + 
  stat_summary(data=data_searcher, fun.data=mean_se, geom='line', size=0.5, aes(color=noise, linetype=searcher)) + 
  coord_cartesian(xlim=c(3,7), ylim=c(0,20)) +
  xlab("Foveal target visibility (d')") + ylab("Number of fixations") +
  scale_color_manual(name='Noise level', values=c('red', 'blue')) +
  scale_fill_manual(name='Noise level', values=c('red', 'blue')) +
  scale_shape_manual(name='Searcher (human)', values=c(1,16)) +
  scale_linetype_manual(name='Searcher (model)', values=c('solid', 'dashed')) +
  theme_classic()
```

Figure 4a of the original paper:

<p align="center"><img width=50% height=50% src="figures/figure_original.png"></p><a name="original_figure"></a>


### Exploratory analyses

In the main analysis, human behavior was compared against the random searcher model. Here, an exploratory analysis was done to compare human behavior to the ideal searcher model. 

```{r}
data_compare_ideal = data_searcher %>% select(visibility, noise, searcher, n_fixation) %>% filter(searcher=='ideal')
data_compare_ideal = rbind(data_compare_ideal, data_human_compare)
data_compare_ideal = data_compare_ideal %>% mutate(searcher = ifelse(searcher=='ideal', 'ideal', 'human')) # collapse human observers for linear model comparison
data_compare_ideal = data_compare_ideal %>% filter(visibility>=3, visibility<=7) # original study visibility range

null_ideal = lm(n_fixation ~ visibility*noise, data=data_compare_ideal)
full_ideal = lm(n_fixation ~ visibility*noise*searcher, data=data_compare_ideal)

# summary of each model
summary(null_ideal)
summary(full_ideal)

anova(null_ideal, full_ideal)
print(paste("Δeta-squared:", summary(full_ideal)$r.squared - summary(null_ideal)$r.squared))
```

Here, the full model led to a significantly improved fit over the null model, implying that the data differs from the **ideal searcher behavior**. Specifically, the null model's $\eta^2$ was `r round(summary(null_ideal)$r.squared,3)` and the full model's $\eta^2$ was `r round(summary(full_ideal)$r.squared,3)`, the difference being $\Delta \eta^2=$ `r round(summary(full_ideal)$r.squared-summary(null_ideal)$r.squared,3)`.


## Discussion

### Summary of Reproduction Attempt
Overall, the main hypothesis (difference between the human search performance versus random searcher performance) was supported in this replication project, by hierarchical linear model comparison. In this aspect, this attempt successfully reproduced the original study.

### Commentary
While supporting the main hypothesis, the exploratory analysis revealed that human performance significantly deviated from the ideal searcher prediction as well. Since no formal statistical testing was performed in the original paper, an alternative formulation of a replication project may conclude that this is a failure of the replication of the original findings. This may strike as suspicious, as the ideal searcher model was intended to reveal a "normative" behavioral pattern.  

It is worth noting that the lack of 'detection task' data in this replication attempt required for completely estimating a participant's visibility map might have resulted in the underestimation of the $d'$ value -- the abscissa -- for a given target contrast level, resulting in the supra-threshold psychophysical range. Intriguingly, a recent study by Zhou and Yu (2021, Communications Biology) using the same stimulus vignette reported the contrast range $[0.111,0.135]$ for the noise background $0.2$, while this replication study reports the contrast levels $0.188$ for A, and $0.19$ for B, for the same noise background condition. An interesting follow-up experiment, beyond the scope of this replication project, might be investigating the near-threshold behavior of visual search.